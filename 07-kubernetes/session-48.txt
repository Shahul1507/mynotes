                                        --------------
                                        | KUBERNETES |  
                                        --------------
                                            DAY-1
                                        -------------		
                                        |  CONTENT  | 
                                        -------------
                                 ---> Need for Kubernetes
                                 ---> Installation using eksctl
                                 ---> Resources
                                      -- namespaces
                                      -- pods 




1. building the images --> Dockerfile
2. running the images --> Containers(docker compose)

we have to create a user and group
all the related mysql directories we should give permissions to this group and user

/var/lib/mysql
/var/run/mysqld
/docker-entrypoint-initdb.d

disadvantages
---------------
1 PG 50 rooms...
no water for 5 days

another 5 PG. either he get water from there or he shift persons to another PG

there is no relibility since there is only one docker host...
there is no autoscaling
there is no load balancing
volumes are inside docker host..poor volume management
security. no secret management
no communication between containers in another host.. network management is not good

--> Because of the disadvantages in docker 
   -- we have "orchestration"
orchestration
--------------
--> (In Docker) -- we have "Docker swarn" for (orchestration) but its poor 
    so,we use 
--> (Kubernetes) for flexible orchestration    

kubernetes Install 
-------------------
--> we need;
   -- (kubectl) --> k8 client command
   -- (eksctl) --> command to create, update and delete cluster. managing cluster

STEPS:
-----   
1.Docker Install
-----------------
    --> create instance (workstation) with 50gb volume --> (configure storage)
    --> Install docker in the server (install-docker.sh)
        {
            -- login to server 
            -- curl https://raw.githubusercontent.com/Shahul1507/expense-docker/refs/heads/main/install-docker.sh | sudo bash
        }
    --> re-size the disk (proper partition) 
        {
        
            -- we have added the storage ,yet we need to partition as per our requirement
            -- follow "resize-disk.md" to do the partition
               -- lsblk
               -- sudo growpart /dev/nvme0n1 4 
               -- sudo lvextend -l +50%FREE /dev/RootVG/rootVol
               -- sudo lvextend -l +50%FREE /dev/RootVG/varVol
               -- sudo xfs_growfs /
               -- sudo xfs_growfs /var
            -- check disk memory now: "df -hT"
            -- exit from root access: "exit"
        }

2.Install kubectl
-----------------
    --> open-link : https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html#linux_amd64_kubectl
    --> check -- Linux (amd64)
    --> curl -O https://s3.us-west-2.amazonaws.com/amazon-eks/1.31.0/2024-09-12/bin/linux/amd64/kubectl
    --> chmod +x ./kubectl
    --> sudo mv kubectl /usr/local/bin/kubectl
    --> kubectl version


3.Install eksctl
---------------- 
    --> open-link: https://eksctl.io/installation/
    --> check -- For unix
    # for ARM systems, set ARCH to: `arm64`, `armv6` or `armv7`
    --> ARCH=amd64
    --> PLATFORM=$(uname -s)_$ARCH
    --> curl -sLO "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_$PLATFORM.tar.gz"
    # (Optional) Verify checksum
    #curl -sL "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_checksums.txt" | grep $PLATFORM | sha256sum --check
    --> tar -xzf eksctl_$PLATFORM.tar.gz -C /tmp && rm eksctl_$PLATFORM.tar.gz
    --> sudo mv /tmp/eksctl /usr/local/bin
    --> eksctl version

4.run aws configure
---------------------
    --> aws configure
    --> provide "AWS Access Key ID"
    --> provide "AWS Secret Access Key"
    --> provide "Default region name"
    --> press "enter"


    
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: expense-1
  region: us-east-1

managedNodeGroups:
  - name: ng-1
    instanceType: m5.large
    desiredCapacity: 10
	spot: true
	
eksctl create cluster --config-file=eks.yaml

	
spot instances
------------------
AWS have huge data center. there may be unused capacity in data center

spot instances --> 90% discount. when AWS requires capacity to ondemand clients they take back instances with 2min notice...


kubectl get nodes --> how many nodes are there in cluster


===========
Resources
===========

--> namespace -- (just like VPC, you will have a dedicated isolated project to create your workloads/resources)
    ----------
{    
    -- create a folder "k8-resources" in vs-code (local)
    -- create a file "01-namespace.yaml"
    -- check the link (https://kubernetes.io/docs/tasks/administer-cluster/namespaces-walkthrough/)
    -- copy the namespace file in "01-namespace.yaml"
       --> 01-namespace.yaml
           ------------------
            apiVersion: v1
            kind: Namespace
            metadata:
              name: expense
              labels:
                project: expense
                environment: dev
    (pushing to git-hub)
    -- cd repo/k8-resources 
    -- git init           
    -- git branch -M main
    -- create repo "k8-resources" in git hub
    -- git remote add origin https://github.com/Shahul1507/k8-resources.git
    -- git add . ; git commit -m "k8-resources"; git push origin main
    
    (pulling to workstation)--Mobaxterm
    -- git clone https://github.com/Shahul1507/k8-resources.git  
    -- cd k8-resources
    -- ls -l 
    -- kubectl apply -f 01-namespace.yaml (namespace created)
    -- kubectl get namespaces (shows the list of namespaces)
}
========================================================================================================
========================================================================================================    

  
--> POD -- (pod is the smallest deployable unit in kubernetes. pod can contain one or many containers.)
   -----
( SINGLE CONTAINER ) 
--------------------  
{
   -- create a file "02-pod.yaml" in "k8-resources" in vs-code (local)
   -- check the link (https://kubernetes.io/docs/concepts/workloads/pods/)
   -- copy the pod file in "02-pod.yaml"
      --> 02-pod.yaml
          ------------
          apiVersion: v1
          kind: Pod
          metadata:
            name: nginx
          spec:
            containers:
            # equivalent to -- docker run -d --name nginx nginx
            - name: nginx
              image: nginx

  (pushing to git-hub)
   -- git add . ; git commit -m "k8-resources"; git push origin main

  (pulling to workstation)--Mobaxterm
   -- git pull
   -- kubectl apply -f 02-pods.yaml (pod created)
   -- kubectl get pods (shows the list of pods)
   -- kubectl exec -it <pod-name> --bash (loging to running pod )
      # curl localhost
      # exit
}      
===========================================================================================
(MULTI-CONTAINER)
-----------------
{
      -- create a file "03-multi-container.yaml" in "k8-resources" in vs-code (local)
      -- check the link (https://kubernetes.io/docs/concepts/workloads/pods/)
      -- copy the pod file in "03-multi-container.yaml"
         --> 03-multi-container.yaml
             -----------------------
             apiVersion: v1
             kind: Pod
             metadata:
               name: multi-container
             spec:
               containers:
               - name: nginx
                 image: nginx
               - name: almalinux:9
                 image: almalinux:9
                 command: ["sleep","100"]
     (pushing to git-hub)
      -- git add . ; git commit -m "k8-resources"; git push origin main
   
     (pulling to workstation)--Mobaxterm
      -- git pull
      -- kubectl apply -f 03-multi-container.yaml (pod created)
      -- kubectl get pods (CrashLoopBackOff - Error)
      -- change "command: ["sleep","1000"]"
      -- kubectl apply -f 03-multi-container.yaml (we get the error)
      (when there is a change in script "delete & recreate" the pod)
      -- kubectl delete -f 03-multi-container.yaml 
      -- kubectl apply -f 03-multi-container.yaml
      -- kubectl get pods
      -- kubectl exec -it multi-container -c --bash (-c - specific container) (loging to running pod )
         # curl localhost
           --  we see both containers are visible in same pod which are sharong identity and storage  
          
}

setup
------
assignment
-------------
1. there is a docker host running
2. no space left on device
3. you need to add extra disk to the running instance
4. make sure docker directory /var/lib/docker is mounted to new disk
5. migrate existing data to new mount
pod vs container
------------------
1. pod is the smallest deployable unit in kubernetes
2. pod can contain one or many containers.
3. containers in a pod can share same network identity and storage
4. these are useful in sidecar and proxy patterns




kubectl exec -it nginx -- bash

pod-1 have nginx container is there
pod-2 can have nginx container or not?

pod-2
---------
1. nginx
2. nginx with name also nginx
3. 

CrashLoopBackOff
-----------------
container is not able to start


Interview:
----------
Q)  pod vs container ?    
A)  1. pod is the smallest deployable unit in kubernetes
    2. pod can contain one or many containers.
    3. containers in a pod can share same network identity and storage
    4. these are useful in sidecar and proxy patterns
 
Q) How can you login to running pod ? 
A) By using cmd [kubectl exec -it <pod-name> -- bash]

Q) what is "crash loop backoff"?
A) When a container is not able to start ,we get the status of "crashLoopBackOff"
   K8s automatically runs the containers putting to status "RunContainerError"


